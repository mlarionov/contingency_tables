{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian probability mass estimation using TensorFlow\n",
    "\n",
    "I have spent some time studying data with categorical variables trying to explore many ways to encode them into numeric features. What if all your variables are categorical? One of the mechanism to describe this scenario known as **contingency tables**.\n",
    "\n",
    "Contingency tables in their essence are (potentially multidimensional) tables where rows, columns and other dimensions represent categorical variables, and the cells contain counts of the occurrences of the combinations. As an example, consider a simple contingency table that represents salary (rows) vs. years of experience (columns). The data are taken from [1] and reported by a study conducted by the Department of Energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_experience_array = np.array([[7,1,1,0,0,0,0,2,0],\n",
    "                                  [10,6,5,3,0,1,1,1,0],\n",
    "                                   [12,14,7,1,4,2,2,1,2],\n",
    "                                   [0,1,8,3,3,3,5,0,4],\n",
    "                                   [0,0,3,2,0,6,5,2,7],\n",
    "                                   [1,0,1,0,1,1,6,0,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_data_frame(data):\n",
    "    return pd.DataFrame(data, index=['950-1350', '1351-1750','1751-2150','2151-2550','2551-2950','2951-3750'],\n",
    "                                columns=['0-2', '3-5', '6-8', '9-11', '12-14', '15-17', '18-23', '24-29', '30+'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-2</th>\n",
       "      <th>3-5</th>\n",
       "      <th>6-8</th>\n",
       "      <th>9-11</th>\n",
       "      <th>12-14</th>\n",
       "      <th>15-17</th>\n",
       "      <th>18-23</th>\n",
       "      <th>24-29</th>\n",
       "      <th>30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950-1350</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351-1750</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751-2150</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151-2550</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551-2950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951-3750</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0-2  3-5  6-8  9-11  12-14  15-17  18-23  24-29  30+\n",
       "950-1350     7    1    1     0      0      0      0      2    0\n",
       "1351-1750   10    6    5     3      0      1      1      1    0\n",
       "1751-2150   12   14    7     1      4      2      2      1    2\n",
       "2151-2550    0    1    8     3      3      3      5      0    4\n",
       "2551-2950    0    0    3     2      0      6      5      2    7\n",
       "2951-3750    1    0    1     0      1      1      6      0    2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_experience = to_data_frame(salary_experience_array)\n",
    "salary_experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of probability mass estimation is to learn probabilities of every combination of categories. A naive approach would be to set the probabilities as fractions of observed cell count and total sample size:\n",
    "\n",
    "$$ p_{ij} = \\frac{m_{ij}}{N},  $$\n",
    "\n",
    "where $m_{ij}$ is the cell count. This is called a *saturated* model and it fits the training data perfectly, but usually suffers from poor generalization due to its excessive complexity. One of the symptoms of its poor generalization is that it predicts zero probabilities for all cells with zero count. But zero cell counts can be due to the small sample size, not due to the probabilities being zero. \n",
    "\n",
    "To address this problem various smoothing techniques were proposed. In essence, all of them update the cell probabilities based on some prior assumptions to correct the extreme values of cell counts. One such smoothing assumption is that the variable may be independent, meaning that the joint probability is a product of the probabities of of individual variables:\n",
    "\n",
    "$$ p_{ij} = p_{i+} p_{+j} $$\n",
    "\n",
    "Here the plus in $p_{i+}$ indicates that we take a sum over the second variable: \n",
    "\n",
    "$$ p_{i+} = \\sum_k{p_{ik}} $$\n",
    "\n",
    "In terms of cell counts this would mean:\n",
    "\n",
    "$$ m_{ij} = \\frac{m_{i+} m_{+j}}{N}, $$\n",
    "\n",
    "where $N$ is the sample size.\n",
    "\n",
    "If we assume the variables are independent, we get the following smoothed contingency matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-2</th>\n",
       "      <th>3-5</th>\n",
       "      <th>6-8</th>\n",
       "      <th>9-11</th>\n",
       "      <th>12-14</th>\n",
       "      <th>15-17</th>\n",
       "      <th>18-23</th>\n",
       "      <th>24-29</th>\n",
       "      <th>30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950-1350</th>\n",
       "      <td>2.2449</td>\n",
       "      <td>1.6463</td>\n",
       "      <td>1.8707</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.5986</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>1.4218</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>1.1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351-1750</th>\n",
       "      <td>5.5102</td>\n",
       "      <td>4.0408</td>\n",
       "      <td>4.5918</td>\n",
       "      <td>1.6531</td>\n",
       "      <td>1.4694</td>\n",
       "      <td>2.3878</td>\n",
       "      <td>3.4898</td>\n",
       "      <td>1.1020</td>\n",
       "      <td>2.7551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751-2150</th>\n",
       "      <td>9.1837</td>\n",
       "      <td>6.7347</td>\n",
       "      <td>7.6531</td>\n",
       "      <td>2.7551</td>\n",
       "      <td>2.4490</td>\n",
       "      <td>3.9796</td>\n",
       "      <td>5.8163</td>\n",
       "      <td>1.8367</td>\n",
       "      <td>4.5918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151-2550</th>\n",
       "      <td>5.5102</td>\n",
       "      <td>4.0408</td>\n",
       "      <td>4.5918</td>\n",
       "      <td>1.6531</td>\n",
       "      <td>1.4694</td>\n",
       "      <td>2.3878</td>\n",
       "      <td>3.4898</td>\n",
       "      <td>1.1020</td>\n",
       "      <td>2.7551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551-2950</th>\n",
       "      <td>5.1020</td>\n",
       "      <td>3.7415</td>\n",
       "      <td>4.2517</td>\n",
       "      <td>1.5306</td>\n",
       "      <td>1.3605</td>\n",
       "      <td>2.2109</td>\n",
       "      <td>3.2313</td>\n",
       "      <td>1.0204</td>\n",
       "      <td>2.5510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951-3750</th>\n",
       "      <td>2.4490</td>\n",
       "      <td>1.7959</td>\n",
       "      <td>2.0408</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>1.0612</td>\n",
       "      <td>1.5510</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>1.2245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0-2     3-5     6-8    9-11   12-14   15-17   18-23   24-29  \\\n",
       "950-1350   2.2449  1.6463  1.8707  0.6735  0.5986  0.9728  1.4218  0.4490   \n",
       "1351-1750  5.5102  4.0408  4.5918  1.6531  1.4694  2.3878  3.4898  1.1020   \n",
       "1751-2150  9.1837  6.7347  7.6531  2.7551  2.4490  3.9796  5.8163  1.8367   \n",
       "2151-2550  5.5102  4.0408  4.5918  1.6531  1.4694  2.3878  3.4898  1.1020   \n",
       "2551-2950  5.1020  3.7415  4.2517  1.5306  1.3605  2.2109  3.2313  1.0204   \n",
       "2951-3750  2.4490  1.7959  2.0408  0.7347  0.6531  1.0612  1.5510  0.4898   \n",
       "\n",
       "              30+  \n",
       "950-1350   1.1224  \n",
       "1351-1750  2.7551  \n",
       "1751-2150  4.5918  \n",
       "2151-2550  2.7551  \n",
       "2551-2950  2.5510  \n",
       "2951-3750  1.2245  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = np.sum(salary_experience_array, axis=1, keepdims=True)\n",
    "m2 = np.sum(salary_experience_array, axis=0, keepdims=True).reshape(1, -1)\n",
    "m12 = m1 * m2 / np.sum(salary_experience_array)\n",
    "independent = to_data_frame(m12)\n",
    "pd.set_option('precision', 4)\n",
    "independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cell counts are very different from the source table. In fact it seems that the independence model does not fit the data well. In statistics there are independence tests specifically designed for contingency tables, but here we are not trying to prove or reject the independence hypothesis. But we will use this hypothesis as our prior belief.\n",
    "\n",
    "For each of the model we would like to measure two things: how well the model fits data and how dependent on each other are the categorical variables. The first is measured using categorical cross entropy, the second using mutual information:\n",
    "\n",
    "$$ I = \\sum_{ij}{p_{ij}log\\big(\\frac{p_{ij}}{p_{i+}p_{+j}}\\big)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(actual, estimated):\n",
    "    \"\"\"\n",
    "    Returns the mutual information as a measure of dependence\n",
    "    and adjusted cross-entropy as a measure of fit\n",
    "    \"\"\"\n",
    "    epsilon = 1E-10\n",
    "    m1 = np.sum(estimated, axis=1, keepdims=True)\n",
    "    m2 = np.sum(estimated, axis=0, keepdims=True).reshape(1, -1)\n",
    "    m12 = m1 * m2 / np.sum(estimated)\n",
    "    log_data = np.where(estimated > 0, np.log(estimated/m12 + epsilon), 0)\n",
    "    inf_mat = estimated * log_data / np.sum(estimated)\n",
    "    \n",
    "    log_likelihood = actual * \\\n",
    "        np.where(actual > 0, np.log(estimated / np.sum(estimated) + epsilon), 0)\n",
    "    \n",
    "    return {\"Dependence\" : round(np.sum(inf_mat),5), \n",
    "            \"Fit to data\": round(-np.sum(log_likelihood) - 492.63557257142736, 5)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completely smoothed data we get the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dependence': 0.0, 'Fit to data': 61.02768}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(salary_experience_array, independent.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model of complete independence does not fit data very well. From the other hand, the saturated model fits data perfectly, but implies high degree of variable dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dependence': 0.41515, 'Fit to data': -0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(salary_experience_array, salary_experience_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Bayesian approach, we would like to encode independence assumption as a prior distribution. First we construct the likelihood function as a product of Multinomial distributions:\n",
    "\n",
    "$$L(p) = N!\\prod_{ij}{\\frac{p_{ij}^{m_{ij}}}{m_{ij}!}}$$\n",
    "\n",
    "Our prior belief is that both dimensions are independent, that is \n",
    "\n",
    "$$ p_{ij} = p_{i+} p_{+j} $$\n",
    "\n",
    "So we constrict the prior distribution as a Dirichlet distribution that is centered around $ p_{i+} p_{+j} $:\n",
    "\n",
    "$$ f_{piror}(p) \\propto \\prod_{ij}{\\Gamma(\\lambda p_{i+} p_{+j})^{-1}p_{ij}^{\\lambda p_{i+} p_{+j}}},  $$\n",
    "\n",
    "where $\\lambda$ is a hyperparameter of the model, and $\\Gamma(x)$ is [the Gamma function](https://en.wikipedia.org/wiki/Gamma_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the cost function (negative log-posterior) will be this:\n",
    "\n",
    "$$ \\mathcal{L} = -\\sum_{ij}({m_{ij} + \\lambda p_{i+} p_{+j})log p_{ij}} + \\sum_{ij}{log \\Gamma(\\lambda p_{i+} p_{+j})}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a non-linear function with respect to the parameter $p$ and it cannot be minimized analytically. For this reason will use an optimization framework that can optimize non-linear functions. I picked TensorFlow for this purpose, but other frameworks can also be used. The code to run the experiment is pretty simple, but I will walk you through it to explain the details and gotchas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, regularization, epochs, verbose=False):\n",
    "    \n",
    "    shape = data.shape\n",
    "      \n",
    "    c_init = tf.zeros_initializer()\n",
    "    c = tf.Variable(initial_value=c_init(shape=shape, dtype=\"float32\"), trainable=True)\n",
    "    \n",
    "    def _get_probabilities():\n",
    "        c_flattened = tf.reshape(c, (1,-1))\n",
    "        p = tf.reshape(tf.nn.softmax(c_flattened), shape)\n",
    "        log_p = tf.reshape(tf.nn.log_softmax(c_flattened), shape)\n",
    "        return p, log_p\n",
    "    \n",
    "    def compute_loss():\n",
    "        epsilon = 1E-10\n",
    "        p, log_p = _get_probabilities()\n",
    "        p1 = tf.reduce_sum(p, axis=1, keepdims=True)\n",
    "        p2 = tf.reshape(tf.reduce_sum(p, axis=0, keepdims=True), (1, -1))\n",
    "        p12 = p1 * p2\n",
    "        loss_array = - (data + regularization * p12) * log_p + \\\n",
    "            tf.math.lgamma(regularization * p12 + epsilon)\n",
    "        return tf.reduce_mean(loss_array, axis=None)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3.0)\n",
    "    for i in range(epochs):\n",
    "        optimizer.minimize(compute_loss, var_list=[c])\n",
    "        if (i % 20 == 0) and verbose:\n",
    "            print(compute_loss().numpy())\n",
    "    \n",
    "    \n",
    "    return _get_probabilities()[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the quick rundown of the code:\n",
    "1. The probabilities $p_{ij}$ take the values between 0 and 1 and should all add up to 1. For this reason I used a common trick and use `softmax` function that takes a variable $c$ and produces $p$ that satisfies these constraints. Correspondingly, the model learns the values of $c$.\n",
    "1. TensorFlow also provides function `log_softmax` that helps avoid the case of extreme large values returned by `softmax`\n",
    "1. The code is using TensorFlow 2.0. So instead of using `Session.run()` we just call a function (in our case `_get_probabilities()`). Honestly, I don't miss TensorFlow 1.x\n",
    "1. To compute $p_{i+} p_{+j}$ we use matrix multiplication. It is the fastest way.\n",
    "1. Function `lgamma()` is used instead of computing Gamma function first then taking a log\n",
    "1. Gamma function of zero is not defined. This makes the cost function unstable. To deal with that we add a small positive value `epsilon` to the argument, which takes care of the issue.\n",
    "1. We have a custom training loop and using Adam optimizer. \n",
    "1. The function returns an Numpy array of probabilities.\n",
    "\n",
    "Let's train the model for several values of the regularization parameter $\\lambda$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dependence': 0.41516, 'Fit to data': 0.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_experiment(salary_experience_array, 0, 200, False)\n",
    "metric(salary_experience_array, result * np.sum(salary_experience_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-2</th>\n",
       "      <th>3-5</th>\n",
       "      <th>6-8</th>\n",
       "      <th>9-11</th>\n",
       "      <th>12-14</th>\n",
       "      <th>15-17</th>\n",
       "      <th>18-23</th>\n",
       "      <th>24-29</th>\n",
       "      <th>30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950-1350</th>\n",
       "      <td>7.00018e+00</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>1.99981e+00</td>\n",
       "      <td>4.35136e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351-1750</th>\n",
       "      <td>9.99979e+00</td>\n",
       "      <td>5.99975e+00</td>\n",
       "      <td>5.00068</td>\n",
       "      <td>3.00008e+00</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>4.35136e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751-2150</th>\n",
       "      <td>1.19995e+01</td>\n",
       "      <td>1.39998e+01</td>\n",
       "      <td>7.00018</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>3.99997e+00</td>\n",
       "      <td>1.99981e+00</td>\n",
       "      <td>1.99981e+00</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>1.99981e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151-2550</th>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>8.00024</td>\n",
       "      <td>3.00008e+00</td>\n",
       "      <td>3.00008e+00</td>\n",
       "      <td>3.00008e+00</td>\n",
       "      <td>5.00068e+00</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>3.99997e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551-2950</th>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>3.00008</td>\n",
       "      <td>1.99981e+00</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>5.99975e+00</td>\n",
       "      <td>5.00068e+00</td>\n",
       "      <td>1.99981e+00</td>\n",
       "      <td>7.00018e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951-3750</th>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>9.99985e-01</td>\n",
       "      <td>5.99975e+00</td>\n",
       "      <td>4.35136e-10</td>\n",
       "      <td>1.99981e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0-2          3-5      6-8         9-11        12-14  \\\n",
       "950-1350   7.00018e+00  9.99985e-01  0.99999  4.35136e-10  4.35136e-10   \n",
       "1351-1750  9.99979e+00  5.99975e+00  5.00068  3.00008e+00  4.35136e-10   \n",
       "1751-2150  1.19995e+01  1.39998e+01  7.00018  9.99985e-01  3.99997e+00   \n",
       "2151-2550  4.35136e-10  9.99985e-01  8.00024  3.00008e+00  3.00008e+00   \n",
       "2551-2950  4.35136e-10  4.35136e-10  3.00008  1.99981e+00  4.35136e-10   \n",
       "2951-3750  9.99985e-01  4.35136e-10  0.99999  4.35136e-10  9.99985e-01   \n",
       "\n",
       "                 15-17        18-23        24-29          30+  \n",
       "950-1350   4.35136e-10  4.35136e-10  1.99981e+00  4.35136e-10  \n",
       "1351-1750  9.99985e-01  9.99985e-01  9.99985e-01  4.35136e-10  \n",
       "1751-2150  1.99981e+00  1.99981e+00  9.99985e-01  1.99981e+00  \n",
       "2151-2550  3.00008e+00  5.00068e+00  4.35136e-10  3.99997e+00  \n",
       "2551-2950  5.99975e+00  5.00068e+00  1.99981e+00  7.00018e+00  \n",
       "2951-3750  9.99985e-01  5.99975e+00  4.35136e-10  1.99981e+00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = to_data_frame(result)\n",
    "probabilities* np.sum(salary_experience_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the predicted counts match the training data very closely. Let's see what the predictions would be for high value of regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dependence': 0.01823, 'Fit to data': 41.26035}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_experiment(salary_experience_array, 500, 100, False)\n",
    "metric(salary_experience_array, result * np.sum(salary_experience_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-2</th>\n",
       "      <th>3-5</th>\n",
       "      <th>6-8</th>\n",
       "      <th>9-11</th>\n",
       "      <th>12-14</th>\n",
       "      <th>15-17</th>\n",
       "      <th>18-23</th>\n",
       "      <th>24-29</th>\n",
       "      <th>30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950-1350</th>\n",
       "      <td>3.38174</td>\n",
       "      <td>1.60395</td>\n",
       "      <td>1.87039</td>\n",
       "      <td>0.68084</td>\n",
       "      <td>0.68074</td>\n",
       "      <td>0.93380</td>\n",
       "      <td>1.20386</td>\n",
       "      <td>1.02942</td>\n",
       "      <td>1.03341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351-1750</th>\n",
       "      <td>6.01283</td>\n",
       "      <td>4.24254</td>\n",
       "      <td>4.69361</td>\n",
       "      <td>2.21369</td>\n",
       "      <td>1.36878</td>\n",
       "      <td>2.31144</td>\n",
       "      <td>2.69139</td>\n",
       "      <td>1.40190</td>\n",
       "      <td>2.14210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751-2150</th>\n",
       "      <td>8.47464</td>\n",
       "      <td>7.62323</td>\n",
       "      <td>7.02657</td>\n",
       "      <td>2.62612</td>\n",
       "      <td>3.14746</td>\n",
       "      <td>3.58306</td>\n",
       "      <td>4.34500</td>\n",
       "      <td>2.05495</td>\n",
       "      <td>3.76672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151-2550</th>\n",
       "      <td>3.69015</td>\n",
       "      <td>3.08018</td>\n",
       "      <td>5.13886</td>\n",
       "      <td>2.19541</td>\n",
       "      <td>2.05561</td>\n",
       "      <td>2.68246</td>\n",
       "      <td>3.58932</td>\n",
       "      <td>1.13517</td>\n",
       "      <td>2.97027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551-2950</th>\n",
       "      <td>3.39100</td>\n",
       "      <td>2.54829</td>\n",
       "      <td>3.81662</td>\n",
       "      <td>1.89522</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>3.16261</td>\n",
       "      <td>3.39575</td>\n",
       "      <td>1.54948</td>\n",
       "      <td>3.48342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951-3750</th>\n",
       "      <td>2.20832</td>\n",
       "      <td>1.55586</td>\n",
       "      <td>2.11060</td>\n",
       "      <td>0.78373</td>\n",
       "      <td>0.94152</td>\n",
       "      <td>1.36490</td>\n",
       "      <td>2.67640</td>\n",
       "      <td>0.61857</td>\n",
       "      <td>1.57253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0-2      3-5      6-8     9-11    12-14    15-17    18-23  \\\n",
       "950-1350   3.38174  1.60395  1.87039  0.68084  0.68074  0.93380  1.20386   \n",
       "1351-1750  6.01283  4.24254  4.69361  2.21369  1.36878  2.31144  2.69139   \n",
       "1751-2150  8.47464  7.62323  7.02657  2.62612  3.14746  3.58306  4.34500   \n",
       "2151-2550  3.69015  3.08018  5.13886  2.19541  2.05561  2.68246  3.58932   \n",
       "2551-2950  3.39100  2.54829  3.81662  1.89522  1.24359  3.16261  3.39575   \n",
       "2951-3750  2.20832  1.55586  2.11060  0.78373  0.94152  1.36490  2.67640   \n",
       "\n",
       "             24-29      30+  \n",
       "950-1350   1.02942  1.03341  \n",
       "1351-1750  1.40190  2.14210  \n",
       "1751-2150  2.05495  3.76672  \n",
       "2151-2550  1.13517  2.97027  \n",
       "2551-2950  1.54948  3.48342  \n",
       "2951-3750  0.61857  1.57253  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = to_data_frame(result)\n",
    "probabilities* np.sum(salary_experience_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dependence is much lower, and the predictions is much more smooth, meaning that there are no zeros or exreme values. However the model does not fit very well to the data. How to find optimal regularization parameter $\\lambda$? We will use cross-validation, a common method in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "Our plan is to generate five folds of data and run the train the model for different values of the regularization hyperparameter. For every split we train the model on the training data and test it on the test data. As a metric here we use cross-entropy loss (the first component returning by the `result_metric` function). We use grid search in logarithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single(data, test_fraction):\n",
    "    \"\"\"Create train and test set\"\"\"\n",
    "    test = np.zeros(shape=data.shape)\n",
    "    for i in range(test.shape[0]):\n",
    "        for j in range(test.shape[1]):\n",
    "            test[i,j] = np.sum(np.random.choice([0,1], size=data[i,j], p=[1-test_fraction, test_fraction]))\n",
    "    return data - test, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating 5 folds\n",
    "np.random.seed(2128506)\n",
    "splits = [sample_single(salary_experience_array, 0.2) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(data, regularization, epochs, verbose=False):\n",
    "    cs_sum = 0\n",
    "    for train, test in splits:\n",
    "        result = run_experiment(train, regularization, epochs, verbose)\n",
    "        result_metric = metric(test, result * np.sum(test))\n",
    "        cs_sum += result_metric['Fit to data']\n",
    "    return cs_sum / len(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = {regularization: run_cv(salary_experience_array, regularization, 300) \n",
    "              for regularization in [0,2,4,8,16,64,128, 256]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -277.8866566666667,\n",
       " 2: -314.990695,\n",
       " 4: -316.59107166666666,\n",
       " 8: -318.0676583333333,\n",
       " 16: -319.3135016666667,\n",
       " 64: -320.434535,\n",
       " 128: -320.05407833333334,\n",
       " 256: -319.23017}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(cv_results, index=['Regularization', \"CV Performance\"])\n",
    "results_df.T.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the cross-validation results the best performance of the model happens when $\\lambda = 64$. We can also see that the model performance changes little after $\\lambda = 4$. Perhaps it makes sense to average several models of comparable performance. Let's see the results generated by the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dependence': 0.1763, 'Fit to data': 12.90124}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_experiment(salary_experience_array, 64, 500, False)\n",
    "metric(salary_experience_array, result * np.sum(salary_experience_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-2</th>\n",
       "      <th>3-5</th>\n",
       "      <th>6-8</th>\n",
       "      <th>9-11</th>\n",
       "      <th>12-14</th>\n",
       "      <th>15-17</th>\n",
       "      <th>18-23</th>\n",
       "      <th>24-29</th>\n",
       "      <th>30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950-1350</th>\n",
       "      <td>5.68973</td>\n",
       "      <td>1.30630</td>\n",
       "      <td>1.50247</td>\n",
       "      <td>0.35553</td>\n",
       "      <td>0.32165</td>\n",
       "      <td>0.43054</td>\n",
       "      <td>0.53850</td>\n",
       "      <td>2.22560</td>\n",
       "      <td>0.44372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351-1750</th>\n",
       "      <td>7.71055</td>\n",
       "      <td>5.01276</td>\n",
       "      <td>4.78635</td>\n",
       "      <td>2.98537</td>\n",
       "      <td>0.58018</td>\n",
       "      <td>1.51411</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>1.36694</td>\n",
       "      <td>0.81316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751-2150</th>\n",
       "      <td>9.47247</td>\n",
       "      <td>10.56914</td>\n",
       "      <td>6.71977</td>\n",
       "      <td>1.73339</td>\n",
       "      <td>3.90291</td>\n",
       "      <td>2.61106</td>\n",
       "      <td>2.83336</td>\n",
       "      <td>1.61330</td>\n",
       "      <td>2.59546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151-2550</th>\n",
       "      <td>1.34993</td>\n",
       "      <td>1.69919</td>\n",
       "      <td>6.76907</td>\n",
       "      <td>2.93928</td>\n",
       "      <td>2.88506</td>\n",
       "      <td>2.93574</td>\n",
       "      <td>4.30820</td>\n",
       "      <td>0.53217</td>\n",
       "      <td>3.55131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551-2950</th>\n",
       "      <td>1.20816</td>\n",
       "      <td>0.93791</td>\n",
       "      <td>3.19687</td>\n",
       "      <td>2.07677</td>\n",
       "      <td>0.51816</td>\n",
       "      <td>4.92782</td>\n",
       "      <td>4.20533</td>\n",
       "      <td>2.07660</td>\n",
       "      <td>5.44199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951-3750</th>\n",
       "      <td>1.50375</td>\n",
       "      <td>0.62231</td>\n",
       "      <td>1.57091</td>\n",
       "      <td>0.39049</td>\n",
       "      <td>1.24524</td>\n",
       "      <td>1.29622</td>\n",
       "      <td>5.13467</td>\n",
       "      <td>0.32709</td>\n",
       "      <td>2.04776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0-2       3-5      6-8     9-11    12-14    15-17    18-23  \\\n",
       "950-1350   5.68973   1.30630  1.50247  0.35553  0.32165  0.43054  0.53850   \n",
       "1351-1750  7.71055   5.01276  4.78635  2.98537  0.58018  1.51411  1.66769   \n",
       "1751-2150  9.47247  10.56914  6.71977  1.73339  3.90291  2.61106  2.83336   \n",
       "2151-2550  1.34993   1.69919  6.76907  2.93928  2.88506  2.93574  4.30820   \n",
       "2551-2950  1.20816   0.93791  3.19687  2.07677  0.51816  4.92782  4.20533   \n",
       "2951-3750  1.50375   0.62231  1.57091  0.39049  1.24524  1.29622  5.13467   \n",
       "\n",
       "             24-29      30+  \n",
       "950-1350   2.22560  0.44372  \n",
       "1351-1750  1.36694  0.81316  \n",
       "1751-2150  1.61330  2.59546  \n",
       "2151-2550  0.53217  3.55131  \n",
       "2551-2950  2.07660  5.44199  \n",
       "2951-3750  0.32709  2.04776  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = to_data_frame(result)\n",
    "probabilities* np.sum(salary_experience_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a good balance between prediction smoothness and how well it fit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Here we considered a fully Bayesian approach for contingency table smoothing. This approach is different from pseudo-Bayes approach, where the prior distribution is defined using the data. The approach shows good results and is recommended to use for multidimensional contingency tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
